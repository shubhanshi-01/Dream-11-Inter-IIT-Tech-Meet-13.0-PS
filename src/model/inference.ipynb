{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to 0404d43c_features.csv\n",
      "    boundaries_hcma_w30 sixes_hcma_w30 fifties_hcma_w30 hundreds_hcma_w30  \\\n",
      "172            2.133333       0.766667              0.1               0.0   \n",
      "\n",
      "    ducks_hcma_w30 thirty_run_innings_hcma_w30 caught_hcma_w30  \\\n",
      "172       0.066667                    0.166667        0.733333   \n",
      "\n",
      "    run out_hcma_w30 direct_hcma_w30 stumped_hcma_w30  ...  \\\n",
      "172         0.033333             0.0         0.166667  ...   \n",
      "\n",
      "    wickets_lbw_bowled_hcma_w30 dot_balls_ewma_w5_alpha0.7  \\\n",
      "172                         0.0                     7.4477   \n",
      "\n",
      "    total_runs_ewma_w5_alpha0.7 balls_faced_ewma_w5_alpha0.7  \\\n",
      "172                     13.1818                      13.1491   \n",
      "\n",
      "    strike_rate_ewma_w5_alpha0.7 runs_conceded_ewma_w5_alpha0.7  \\\n",
      "172                   111.195769                            0.0   \n",
      "\n",
      "    balls_bowled_ewma_w5_alpha0.7 economy_rate_ewma_w5_alpha0.7  \\\n",
      "172                           0.0                           0.0   \n",
      "\n",
      "    dots_ewma_w5_alpha0.7 bowling_average_ewma_w5_alpha0.7  \n",
      "172                   0.0                              0.0  \n",
      "\n",
      "[1 rows x 25 columns]\n",
      "---------------------------------\n",
      "     boundaries_hcma_w30  sixes_hcma_w30  fifties_hcma_w30  hundreds_hcma_w30  \\\n",
      "172             1.035027        0.871523          0.331247          -0.246394   \n",
      "\n",
      "     ducks_hcma_w30  thirty_run_innings_hcma_w30  caught_hcma_w30  \\\n",
      "172       -0.021933                      0.66226         1.785108   \n",
      "\n",
      "     run out_hcma_w30  direct_hcma_w30  stumped_hcma_w30  ...  \\\n",
      "172         -0.274293              0.0           0.89786  ...   \n",
      "\n",
      "     wickets_lbw_bowled_hcma_w30  dot_balls_ewma_w5_alpha0.7  \\\n",
      "172                    -0.744118                    0.990822   \n",
      "\n",
      "     total_runs_ewma_w5_alpha0.7  balls_faced_ewma_w5_alpha0.7  \\\n",
      "172                     0.289783                      0.428904   \n",
      "\n",
      "     strike_rate_ewma_w5_alpha0.7  runs_conceded_ewma_w5_alpha0.7  \\\n",
      "172                      0.667856                       -1.002154   \n",
      "\n",
      "     balls_bowled_ewma_w5_alpha0.7  economy_rate_ewma_w5_alpha0.7  \\\n",
      "172                      -1.058458                      -1.063008   \n",
      "\n",
      "     dots_ewma_w5_alpha0.7  bowling_average_ewma_w5_alpha0.7  \n",
      "172              -0.924357                          -0.85433  \n",
      "\n",
      "[1 rows x 25 columns]\n",
      "---------------------------------\n",
      "[{'id': '0404d43c', 'score': tensor([[33.6257]])}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class LargeNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LargeNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.bn5 = nn.BatchNorm1d(32)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc6 = nn.Linear(32, 1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        out = self.fc3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        out = self.fc4(out)\n",
    "        out = self.bn4(out)\n",
    "        out = self.relu4(out)\n",
    "\n",
    "        out = self.fc5(out)\n",
    "        out = self.bn5(out)\n",
    "        out = self.relu5(out)\n",
    "\n",
    "\n",
    "        out = self.fc6(out)  # No activation in output layer (for regression tasks)\n",
    "        return out\n",
    "\n",
    "def mae_loss(y_pred, y_true):\n",
    "    return torch.mean(torch.abs(y_pred - y_true))\n",
    "\n",
    "def rmse_loss(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def get_features(player_id, date, match_type):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    # Constants\n",
    "    cat_1_columns = [\n",
    "        \"boundaries\", \"sixes\", \"fifties\", \"hundreds\", \"ducks\", \"thirty_run_innings\",\n",
    "        \"caught\", \"run out\", \"direct\", \"stumped\", \"3+catches\", \"wickets_taken\",\n",
    "        \"3wickets_haul\", \"5wickets_haul\", \"maiden_overs\", \"wickets_lbw_bowled\"\n",
    "    ]\n",
    "    cat_1_windows = [10, 30, 50]  # Sparse\n",
    "    cat_2_columns = [\n",
    "        \"dot_balls\", \"total_runs\", \"balls_faced\", \"strike_rate\", \"runs_conceded\",\n",
    "        \"balls_bowled\", \"economy_rate\", \"dots\", \"bowling_average\"\n",
    "    ]\n",
    "    cat_2_windows = [3, 5, 7]  # Dense\n",
    "    ewma_alphas = [0.5, 0.7, 0.9]\n",
    "    format_mapping = {\"it20\": \"t20\", \"mdm\": \"test\", \"odm\": \"odi\"}\n",
    "\n",
    "    # Read the player data\n",
    "    input_folder = \"../data/processed/playerwise/\"\n",
    "    file_path = os.path.join(input_folder, f\"{player_id}.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Player data file not found: {file_path}\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Normalize 'match_type' to lowercase and map formats\n",
    "    if 'match_type' in df.columns:\n",
    "        df[\"match_type\"] = df[\"match_type\"].str.lower()\n",
    "        df[\"revised_format\"] = df[\"match_type\"].map(format_mapping).fillna(df[\"match_type\"])\n",
    "    else:\n",
    "        raise ValueError(\"match_type column not found in the data.\")\n",
    "\n",
    "    # Convert 'date' column to datetime\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        date = pd.to_datetime(date)\n",
    "        df = df[df['date'] < date]  # Filter data before the given date\n",
    "    else:\n",
    "        raise ValueError(\"Date column not found in the data; cannot filter by date.\")\n",
    "\n",
    "    # Filter by 'revised_format'\n",
    "    # print(df)\n",
    "    match_type_lower = match_type.lower()\n",
    "    match_type_mapped = format_mapping.get(match_type_lower, match_type_lower)\n",
    "    df = df[df['revised_format'] == match_type_mapped]\n",
    "\n",
    "    # Sort by date\n",
    "    df.sort_values('date', inplace=True)\n",
    "\n",
    "    if df.empty:\n",
    "        feature_columns = []\n",
    "        for window in cat_1_windows:\n",
    "            for col in cat_1_columns:\n",
    "                feature_columns.append(f\"{col}_hcma_w{window}\")\n",
    "        for window in cat_2_windows:\n",
    "            for col in cat_2_columns:\n",
    "                for alpha in ewma_alphas:\n",
    "                    feature_columns.append(f\"{col}_ewma_w{window}_alpha{alpha}\")\n",
    "        features = pd.DataFrame(columns=['player_role'] + feature_columns)\n",
    "        features.loc[0] = [np.nan] * (len(feature_columns) + 1)\n",
    "        features['player_role'] = 'new'\n",
    "        features.to_csv(f\"{player_id}_features.csv\", index=False)  # Save to CSV\n",
    "        return features.iloc[0]\n",
    "\n",
    "    # Determine player role\n",
    "    total_matches = len(df)\n",
    "    bowled_matches = df[df[\"balls_bowled\"] > 0].shape[0]\n",
    "    batted_matches = df[df[\"balls_faced\"] > 0].shape[0]\n",
    "\n",
    "    is_bowler = bowled_matches / total_matches >= 0.25\n",
    "    is_batsman = batted_matches / total_matches >= 0.25\n",
    "\n",
    "    if is_bowler and is_batsman:\n",
    "        player_role = \"all-rounder\"\n",
    "    elif is_bowler:\n",
    "        player_role = \"bowler\"\n",
    "    elif is_batsman:\n",
    "        player_role = \"batsman\"\n",
    "    else:\n",
    "        player_role = \"new\"\n",
    "\n",
    "    # Compute features\n",
    "    results = df.copy()\n",
    "    # print (results)\n",
    "    # Cat-1 (Sparse: HCMA)\n",
    "    cat1_features = {}\n",
    "    for window in cat_1_windows:\n",
    "        for col in cat_1_columns:\n",
    "            col_name = f\"{col}_hcma_w{window}\"\n",
    "            if col in df.columns:\n",
    "                cat1_features[col_name] = (\n",
    "                    df.groupby('revised_format')[col]\n",
    "                    .transform(lambda s: s.shift(1).rolling(window=window, min_periods=1).mean())\n",
    "                )\n",
    "            else:\n",
    "                cat1_features[col_name] = np.nan\n",
    "    results = pd.concat([results, pd.DataFrame(cat1_features)], axis=1)\n",
    "\n",
    "    # Cat-2 (Dense: EWMA)\n",
    "    #print(df)\n",
    "    cat2_features = {}\n",
    "    for window in cat_2_windows:\n",
    "        for col in cat_2_columns:\n",
    "            for alpha in ewma_alphas:\n",
    "                col_name = f\"{col}_ewma_w{window}_alpha{alpha}\"\n",
    "                if col in df.columns:\n",
    "                    cat2_features[col_name] = df.groupby('revised_format')[col].transform(\n",
    "                        lambda s: s.shift(1).rolling(window=window, min_periods=1).apply(\n",
    "                            lambda x: x.ewm(alpha=alpha, adjust=False).mean().iloc[-1] if len(x) > 0 else np.nan\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    cat2_features[col_name] = np.nan\n",
    "    results = pd.concat([results, pd.DataFrame(cat2_features)], axis=1)\n",
    "\n",
    "    # Feature columns\n",
    "    # print(results)\n",
    "    feature_columns = list(cat1_features.keys()) + list(cat2_features.keys())\n",
    "\n",
    "    # Get the last row of features\n",
    "    last_row = results.iloc[-1][feature_columns]\n",
    "    last_row['player_role'] = player_role\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = f\"{player_id}_features.csv\"\n",
    "    last_row.to_frame().T.to_csv(output_file, index=False)\n",
    "    print(f\"Features saved to {output_file}\")\n",
    "\n",
    "    return last_row\n",
    "\n",
    "\n",
    "def model_inference(last_row):\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "\n",
    "    # Convert last_row (Series) to DataFrame\n",
    "    features_df = last_row.to_frame().T  # Transpose to get a DataFrame\n",
    "\n",
    "    # Define the feature columns\n",
    "    cat_1_columns = [\n",
    "        \"boundaries\",\n",
    "        \"sixes\",\n",
    "        \"fifties\",\n",
    "        \"hundreds\",\n",
    "        \"ducks\",\n",
    "        \"thirty_run_innings\",\n",
    "        \"caught\",\n",
    "        \"run out\",\n",
    "        \"direct\",\n",
    "        \"stumped\",\n",
    "        \"3+catches\",\n",
    "        \"wickets_taken\",\n",
    "        \"3wickets_haul\",\n",
    "        \"5wickets_haul\",\n",
    "        \"maiden_overs\",\n",
    "        \"wickets_lbw_bowled\",\n",
    "    ]\n",
    "\n",
    "    cat_2_columns = [\n",
    "        \"dot_balls\",\n",
    "        \"total_runs\",\n",
    "        \"balls_faced\",\n",
    "        \"strike_rate\",\n",
    "        \"runs_conceded\",\n",
    "        \"balls_bowled\",\n",
    "        \"economy_rate\",\n",
    "        \"dots\",\n",
    "        \"bowling_average\",\n",
    "    ]\n",
    "\n",
    "    numerical_features = []\n",
    "    # Construct feature names as per training\n",
    "    window = 30\n",
    "    for col in cat_1_columns:\n",
    "        col_name = f\"{col}_hcma_w{window}\"\n",
    "        numerical_features.append(col_name)\n",
    "\n",
    "    window = 5\n",
    "    alpha = 0.7\n",
    "    for col in cat_2_columns:\n",
    "        col_name = f\"{col}_ewma_w{window}_alpha{alpha}\"\n",
    "        numerical_features.append(col_name)\n",
    "\n",
    "    # Ensure that all necessary features are present\n",
    "    missing_cols = set(numerical_features) - set(features_df.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing columns in input data: {missing_cols}\")\n",
    "        # Handle missing columns (e.g., fill with zeros)\n",
    "        for col in missing_cols:\n",
    "            features_df[col] = 0  # Adjust as necessary for your use case\n",
    "    X = features_df[numerical_features].copy()\n",
    "    # print(\"X:\\n\", X)\n",
    "    scaler_fit = joblib.load(f\"../data/interim/scaler/scaler_{match_type}.save\") \n",
    "    print(features_df[numerical_features])\n",
    "\n",
    "    features_df[numerical_features] = scaler_fit.transform(\n",
    "        features_df[numerical_features]\n",
    "    )\n",
    "    print(\"---------------------------------\")\n",
    "    print(features_df[numerical_features])\n",
    "    # print(features_df[numerical_features].shape)\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "    # Select and prepare the feature columns\n",
    "    X = features_df[numerical_features].copy()\n",
    "    # print(\"X:\\n\", X)\n",
    "    X = X.astype(float)\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "\n",
    "    # Load the ANN model\n",
    "    # Placeholder for model loading\n",
    "    # Adjust input_size and other parameters according to your model\n",
    "    input_size = X_tensor.shape[1]\n",
    "    model = LargeNet(input_size=input_size)\n",
    "    model.load_state_dict(torch.load('../model_artifacts/Product_UI_t20_Model.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)  # Get raw model outputs, which are the predicted scores\n",
    "    \n",
    "    predicted_scores = outputs  # These are your predicted regression scores\n",
    "\n",
    "    # Return the prediction\n",
    "    return predicted_scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(team1, team2, team_players1, team_players2, match_date, match_type):\n",
    "    \"\"\"\n",
    "    Predicts the top 11 players based on the model's inference.\n",
    "    \n",
    "    Args:\n",
    "        team1 (str): Name of Team 1.\n",
    "        team2 (str): Name of Team 2.\n",
    "        team_players1 (list[dict]): List of players in Team 1.\n",
    "        team_players2 (list[dict]): List of players in Team 2.\n",
    "        match_date (str): Date of the match.\n",
    "        match_type (str): Type of the match.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: List of top 11 players' IDs and their predicted scores.\n",
    "    \"\"\"\n",
    "    all_players = team_players1 + team_players2\n",
    "    player_scores = []\n",
    "\n",
    "    # Iterate through all players to compute their scores\n",
    "    for player in all_players:\n",
    "        player_id = player[\"id\"]\n",
    "        features = get_features(player_id, match_date, match_type)\n",
    "        score = model_inference(features)  # Simulate model inference\n",
    "        player_scores.append({\"id\": player_id, \"score\": score})\n",
    "\n",
    "    # Sort players by score in descending order\n",
    "    player_scores.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    # Return the top 11 players with their scores\n",
    "    return player_scores[:11]\n",
    "\n",
    "# Example usage\n",
    "team1 = \"Bangladesh\"\n",
    "team2 = \"India\"\n",
    "team_players2 = []\n",
    "team_players1 = [{\"id\": \"0404d43c\", \"name\": \"Player A1\", \"alt_name\": \"\", \"image\": \"\"}]\n",
    "match_date = \"2024-10-09\"\n",
    "match_type = \"T20\"\n",
    "\n",
    "top_players = predict(team1, team2, team_players1, team_players2, match_date, match_type)\n",
    "print(top_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
